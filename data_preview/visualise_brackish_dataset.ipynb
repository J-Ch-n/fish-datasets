{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing Template\n",
    "This notebook was used to download, analyze and process the data from the NOAA Pudget Sound dataset.\n",
    "\n",
    "You can use this template to process your own dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import supervision as sv\n",
    "from pathlib import Path\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the Data\n",
    "- If you want to use the `unzip` command you might need to install it. On linux, run `sudo apt-get install unzip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_shortname = \"brackish_dataset\"\n",
    "data_dir = Path(\"/tmp/data/\") / dataset_shortname\n",
    "data_dir.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"https://public.roboflow.com/ds/J1rFmOSvu0\\?key=0adJYkLeGN\" # 960x540\n",
    "# data = \"https://public.roboflow.com/ds/XNcGlJKpVd\\?key=ErlvzPXTvT\" # 1920x1080\n",
    "\n",
    "data_path = data_dir/\"data.zip\"\n",
    "\n",
    "!wget -O {data_path} {data}\n",
    "\n",
    "!unzip {data_path} -d {data_dir}\n",
    "\n",
    "!rm {data_path}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the annotations\n",
    "Turn into COCO format readable by `supervision` library, for easy visualization and conversion to other formats.\n",
    "- annotations.json only contains annotations for images with at least one bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "splits = [\"train\", \"valid\", \"test\"]\n",
    "\n",
    "for split in splits:\n",
    "\n",
    "    annotations_path = data_dir / f\"{split}/_annotations.coco.json\"\n",
    "    print(annotations_path)\n",
    "    with open(annotations_path, \"r\") as f:\n",
    "        annotations = json.load(f)\n",
    "        \n",
    "    cleaned_annotations = []\n",
    "        \n",
    "    print(f\"Number of annotations: {len(annotations['annotations'])}\")\n",
    "        \n",
    "    for i, annotation in enumerate(annotations[\"annotations\"]):\n",
    "        if \"bbox\" not in annotation or len(annotation[\"bbox\"]) == 0:\n",
    "            print(f\"No bbox found for {annotation['image_id']}\")\n",
    "        else:\n",
    "            cleaned_annotations.append(annotation)\n",
    "\n",
    "    annotations[\"annotations\"] = cleaned_annotations\n",
    "\n",
    "    with open(annotations_path, \"w\") as f:\n",
    "        print(f\"Number of annotations: {len(annotations['annotations'])}\")\n",
    "        json.dump(annotations, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise\n",
    "To visualise we need to extract the frames from the video, therefore, pick only one video to analyse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "\n",
    "for split in splits:\n",
    "    annotations_path = data_dir / f\"{split}/_annotations.coco.json\"\n",
    "    images_path = data_dir / split\n",
    "    datasets[split] = sv.DetectionDataset.from_coco(\n",
    "        images_directory_path=str(images_path),\n",
    "        annotations_path=str(annotations_path),\n",
    "    )\n",
    "\n",
    "    print(f\"Split: {split}; Dataset length: {len(datasets[split])}\")\n",
    "    print(f\"Split: {split}; Dataset classes: {datasets[split].classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in splits:\n",
    "    box_annotator = sv.BoxAnnotator()\n",
    "    label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "    image_example = None\n",
    "\n",
    "    annotated_images = []\n",
    "    for _ in range(16):\n",
    "        i = random.randint(0, len(datasets[split]))\n",
    "        \n",
    "        _, image, annotations = datasets[split][i]\n",
    "\n",
    "        labels = [datasets[split].classes[class_id] for class_id in annotations.class_id]\n",
    "\n",
    "        annotated_image = image.copy()\n",
    "        annotated_image = box_annotator.annotate(annotated_image, annotations)\n",
    "        annotated_image = label_annotator.annotate(annotated_image, annotations, labels)\n",
    "        annotated_images.append(annotated_image)\n",
    "        \n",
    "        if len(annotations) > 0:\n",
    "            image_example = annotated_image\n",
    "        \n",
    "    sv.plot_images_grid(\n",
    "        annotated_images,\n",
    "        grid_size=(4, 4),\n",
    "        titles=None,\n",
    "        size=(20, 12),\n",
    "        cmap=\"gray\"\n",
    "    )\n",
    "\n",
    "plt.imsave(f\"{dataset_shortname}_sample_image.png\", image_example)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Output\n",
    "- Save example image\n",
    "- Save notebook to visualize the image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fish_detection_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
