{"cells":[{"cell_type":"markdown","source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1lP354J_WD0mwzT1lxBv2zZkZ1LjyXZJM?usp=colab)"],"metadata":{"id":"L7bpCDsqBim_"}},{"cell_type":"markdown","metadata":{"id":"2so4J50AJg_X"},"source":["# Visualise the MegaFauna dataset from the Marine Detect project\n","This notebook was used to download, analyze and process the data from the MegaFauna dataset from the Marine Detect project."]},{"cell_type":"code","source":["!pip install supervision"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FclV0LFcKBlV","executionInfo":{"status":"ok","timestamp":1743273370242,"user_tz":-60,"elapsed":8920,"user":{"displayName":"Alexander Merdian-Tarko","userId":"02819705391358537583"}},"outputId":"3031cf2a-7b3b-420a-e67c-334beb3644ff"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting supervision\n","  Downloading supervision-0.25.1-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: contourpy>=1.0.7 in /usr/local/lib/python3.11/dist-packages (from supervision) (1.3.1)\n","Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from supervision) (0.7.1)\n","Requirement already satisfied: matplotlib>=3.6.0 in /usr/local/lib/python3.11/dist-packages (from supervision) (3.10.0)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from supervision) (2.0.2)\n","Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.11/dist-packages (from supervision) (4.11.0.86)\n","Requirement already satisfied: pillow>=9.4 in /usr/local/lib/python3.11/dist-packages (from supervision) (11.1.0)\n","Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.11/dist-packages (from supervision) (6.0.2)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from supervision) (2.32.3)\n","Requirement already satisfied: scipy<2.0.0,>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from supervision) (1.14.1)\n","Requirement already satisfied: tqdm>=4.62.3 in /usr/local/lib/python3.11/dist-packages (from supervision) (4.67.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision) (4.56.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision) (24.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision) (3.2.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision) (2.8.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->supervision) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->supervision) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->supervision) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->supervision) (2025.1.31)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6.0->supervision) (1.17.0)\n","Downloading supervision-0.25.1-py3-none-any.whl (181 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.5/181.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: supervision\n","Successfully installed supervision-0.25.1\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"MMWfSUjyJg_a","executionInfo":{"status":"ok","timestamp":1743273371123,"user_tz":-60,"elapsed":865,"user":{"displayName":"Alexander Merdian-Tarko","userId":"02819705391358537583"}}},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import supervision as sv\n","from pathlib import Path\n","import random\n","\n","import matplotlib.patches as patches\n","import xml.etree.ElementTree as ET\n","from IPython.display import HTML\n","from PIL import Image\n","import numpy as np\n","import base64\n","import shutil\n","import json\n","import cv2\n","import os\n","import io"]},{"cell_type":"markdown","metadata":{"id":"kVa_X5EEJg_d"},"source":["## Download the Data"]},{"cell_type":"code","source":["dataset_shortname = \"marine_detect_megafauna\"\n","data_url = \"https://stpubtenakanclyw.blob.core.windows.net/marine-detect/MegaFauna-dataset.zip\"\n","data_path = dataset_shortname + \".zip\""],"metadata":{"id":"iY789yW6SVyj","executionInfo":{"status":"ok","timestamp":1743273371147,"user_tz":-60,"elapsed":47,"user":{"displayName":"Alexander Merdian-Tarko","userId":"02819705391358537583"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mq_clWXxJg_h","outputId":"00ba29c6-e0eb-428e-d8e5-171da34beb9a"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2025-03-29 18:36:11--  https://stpubtenakanclyw.blob.core.windows.net/marine-detect/MegaFauna-dataset.zip\n","Resolving stpubtenakanclyw.blob.core.windows.net (stpubtenakanclyw.blob.core.windows.net)... 52.239.143.36\n","Connecting to stpubtenakanclyw.blob.core.windows.net (stpubtenakanclyw.blob.core.windows.net)|52.239.143.36|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2461314593 (2.3G) [application/octet-stream]\n","Saving to: ‘marine_detect_megafauna.zip’\n","\n","t_megafauna.zip       1%[                    ]  34.34M  6.88MB/s    eta 7m 24s "]}],"source":["!wget -nc -O {data_path} {data_url}\n","!if [ ! -d {dataset_shortname} ]; then unzip -q {data_path} -d {dataset_shortname}; fi"]},{"cell_type":"code","source":["images_path = \"images\"\n","annotations_path = \"labels\"\n","annotations_file = \"annotations.json\""],"metadata":{"id":"NP9HYsVq_WVY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def merge_files(root_dir):\n","    \"\"\"\n","    Merges images and labels from train, valid, and test directories into\n","    single 'images/' and 'labels/' directories in the current working directory (PWD),\n","    adding dataset-specific suffixes. Skip OzFish images.\n","\n","    Parameters:\n","    - root_dir: Path where 'train', 'valid', and 'test' directories are located.\n","    \"\"\"\n","\n","    # Define dataset splits\n","    datasets = [(\"train\", \"train\"), (\"valid\", \"valid\"), (\"test\", \"test\")]\n","\n","    # Define target directories in PWD\n","    images_dir = os.path.join(os.getcwd(), \"images\")  # PWD/images/\n","    labels_dir = os.path.join(os.getcwd(), \"labels\")  # PWD/labels/\n","\n","    # Create target directories if they don’t exist\n","    os.makedirs(images_dir, exist_ok=True)\n","    os.makedirs(labels_dir, exist_ok=True)\n","\n","    ignored_count = 0  # Counter for ignored files\n","    skip_patterns = [\"_L.MP4.\", \"_R.MP4.\", \"_L.avi.\", \"_R.avi.\"]  # Patterns to skip\n","    # Files matching this pattern are skipped as they stem from the OzFish dataset and shouldn't be considered twice\n","\n","    for dataset, suffix in datasets:\n","        img_src = os.path.join(root_dir, dataset, \"images\")\n","        lbl_src = os.path.join(root_dir, dataset, \"labels\")\n","\n","        # Copy images\n","        if os.path.exists(img_src):\n","            for file in os.listdir(img_src):\n","                if any(pattern in file for pattern in skip_patterns):\n","                    ignored_count += 1\n","                    continue  # Skip this file\n","\n","                if file.lower().endswith(('.jpg', '.jpeg', '.png')):  # Ensure it's an image\n","                    name, ext = os.path.splitext(file)\n","                    new_filename = f\"{name}_{suffix}{ext}\"\n","                    shutil.copy2(os.path.join(img_src, file), os.path.join(images_dir, new_filename))\n","\n","        # Copy labels\n","        if os.path.exists(lbl_src):\n","            for file in os.listdir(lbl_src):\n","                if any(pattern in file for pattern in skip_patterns):\n","                    ignored_count += 1\n","                    continue  # Skip this file\n","\n","                if file.lower().endswith('.txt'):  # Ensure it's a label file\n","                    name, ext = os.path.splitext(file)\n","                    new_filename = f\"{name}_{suffix}{ext}\"\n","                    shutil.copy2(os.path.join(lbl_src, file), os.path.join(labels_dir, new_filename))\n","\n","    print(f\"All images saved to {images_dir}\")\n","    print(f\"All labels saved to {labels_dir}\")\n","    print(f\"Ignored {ignored_count} images stemming from the OzFish dataset.\")"],"metadata":{"id":"TwmCoBTqqc-U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["merge_files(\"marine_detect_megafauna/notebooks/datasets/MegaFaunaSplit\")"],"metadata":{"id":"DYGDEvcmrvMT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kk2slOJDJg_i"},"source":["### Clean the annotations\n","Turn into COCO format readable by `supervision` library, for easy visualization and conversion to other formats.\n","- annotations.json only contains annotations for images with at least one bounding box"]},{"cell_type":"code","source":["def convert_to_coco(image_dir, label_dir, output_json):\n","    \"\"\"\n","    Converts annotation text files into a COCO format JSON.\n","\n","    Parameters:\n","    - image_dir: Path to the directory containing images.\n","    - label_dir: Path to the directory containing annotation text files.\n","    - output_json: Path to save the output JSON file.\n","    \"\"\"\n","\n","    # Category mapping\n","    categories = [\n","        {\"id\": 0, \"name\": \"ray\"},\n","        {\"id\": 1, \"name\": \"shark\"},\n","        {\"id\": 2, \"name\": \"turtle\"}\n","    ]\n","\n","    # Initialize COCO JSON structure\n","    coco_data = {\n","        \"info\": {\n","            \"description\": \"Dataset in COCO format\",\n","            \"version\": \"1.0\",\n","            \"year\": 2025\n","        },\n","        \"images\": [],\n","        \"annotations\": [],\n","        \"categories\": categories\n","    }\n","\n","    # Counters for unique IDs\n","    image_id = 0\n","    annotation_id = 0\n","\n","    # Process each image file\n","    for image_file in os.listdir(image_dir):\n","        if not image_file.lower().endswith(('.jpg', '.jpeg', '.png')):  # Ensure it's an image\n","            continue\n","\n","        image_name = os.path.basename(image_file)\n","        image_path = os.path.join(image_dir, image_name)\n","        annotation_file = os.path.splitext(image_name)[0] + \".txt\"\n","        annotation_path = os.path.join(label_dir, annotation_file)\n","\n","        # Get image size\n","        with Image.open(image_path) as img:\n","            width, height = img.size\n","\n","        # Add image metadata to COCO format\n","        coco_data[\"images\"].append({\n","            \"id\": image_id,\n","            \"file_name\": image_name,\n","            \"width\": width,\n","            \"height\": height\n","        })\n","\n","        # Check if annotation file exists and is not empty\n","        if os.path.exists(annotation_path) and os.path.getsize(annotation_path) > 0:\n","            with open(annotation_path, \"r\") as f:\n","                for line in f:\n","                    parts = line.strip().split()\n","                    if len(parts) != 5:\n","                        print(f\"Warning: Skipping invalid line in {annotation_file}: {line}\")\n","                        continue\n","\n","                    class_id, x_min, y_min, x_max, y_max = map(float, parts)\n","\n","                    # Convert to COCO format (x, y, width, height)\n","                    bbox = [x_min, y_min, x_max - x_min, y_max - y_min]\n","\n","                    # Add annotation entry\n","                    coco_data[\"annotations\"].append({\n","                        \"id\": annotation_id,\n","                        \"image_id\": image_id,\n","                        \"category_id\": int(class_id),\n","                        \"bbox\": bbox,\n","                        \"area\": bbox[2] * bbox[3],  # width * height\n","                        \"iscrowd\": 0\n","                    })\n","                    annotation_id += 1\n","\n","        # Move to the next image\n","        image_id += 1\n","\n","    # Save to JSON file\n","    with open(output_json, \"w\") as json_file:\n","        json.dump(coco_data, json_file, indent=4)\n","\n","    print(f\"COCO annotations saved to {output_json}\")"],"metadata":{"id":"0oMAlX0dmV99"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["convert_to_coco(images_path, annotations_path, annotations_file)"],"metadata":{"id":"jLtTPhuJmir_"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eKTgWdJ_Jg_j"},"outputs":[],"source":["with open(annotations_file, \"r\") as f:\n","    annotations = json.load(f)\n","\n","cleaned_annotations = []\n","\n","print(f\"Number of annotations: {len(annotations['annotations'])}\")\n","\n","for i, annotation in enumerate(annotations[\"annotations\"]):\n","    if \"bbox\" not in annotation or len(annotation[\"bbox\"]) == 0:\n","        print(f\"No bbox found for {annotation['image_id']}\")\n","    else:\n","        cleaned_annotations.append(annotation)\n","\n","annotations[\"annotations\"] = cleaned_annotations\n","\n","with open(annotations_file, \"w\") as f:\n","    print(f\"Number of annotations: {len(annotations['annotations'])}\")\n","    json.dump(annotations, f)"]},{"cell_type":"markdown","metadata":{"id":"PsfoHEV-Jg_k"},"source":["## Visualise\n"]},{"cell_type":"code","source":["dataset = sv.DetectionDataset.from_coco(\n","    images_directory_path=str(images_path),\n","    annotations_path=str(annotations_file),\n",")\n","\n","print(f\"Dataset length: {len(dataset)}\")\n","print(f\"Dataset classes: {dataset.classes}\")"],"metadata":{"id":"pJR8oP6ulZy6"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ow1fggNgJg_m"},"outputs":[],"source":["# Annotators\n","box_annotator = sv.BoxAnnotator()\n","label_annotator = sv.LabelAnnotator()\n","\n","annotated_images = []\n","\n","# Fixed size for each image in the grid\n","IMAGE_SIZE = (256, 128)  # Uniform image size\n","GRID_SIZE = (4, 4)  # Grid layout\n","DISPLAY_SIZE = (20, 12)  # Overall figure size\n","\n","example_image = None\n","\n","for _ in range(GRID_SIZE[0] * GRID_SIZE[1]):\n","    i = random.randint(0, len(dataset) - 1)\n","    _, image, annotations = dataset[i]\n","    labels = [dataset.classes[class_id] for class_id in annotations.class_id]\n","\n","    # Annotate image\n","    annotated_image = image.copy()\n","    annotated_image = box_annotator.annotate(annotated_image, annotations)\n","    annotated_image = label_annotator.annotate(annotated_image, annotations, labels)\n","\n","    # Ensure we store one sample image for saving later\n","    if example_image is None and len(annotations) > 0:\n","        example_image = annotated_image\n","\n","    # Resize image for consistent display\n","    if isinstance(annotated_image, np.ndarray):\n","        annotated_image = cv2.resize(annotated_image, IMAGE_SIZE, interpolation=cv2.INTER_AREA)\n","    else:\n","        annotated_image = Image.fromarray(annotated_image).resize(IMAGE_SIZE)\n","\n","    annotated_images.append(annotated_image)\n","\n","# Function to encode an image as a Base64 string\n","def encode_image(image):\n","    buf = io.BytesIO()\n","\n","    # Convert PIL Image to NumPy array\n","    if isinstance(image, Image.Image):\n","        image = np.array(image)\n","\n","    # Convert from BGR to RGB if needed\n","    if len(image.shape) == 3 and image.shape[-1] == 3:\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","    # Ensure correct data type\n","    if image.dtype != np.uint8:\n","        image = (image * 255).astype(np.uint8)  # Normalize if float\n","\n","    plt.imsave(buf, image, format=\"png\")\n","    buf.seek(0)\n","    return base64.b64encode(buf.read()).decode(\"utf-8\")\n","\n","# Encode all images\n","encoded_images = [encode_image(img) for img in annotated_images]\n","\n","# Create an HTML grid to display images\n","html = f\"<div style='display: grid; grid-template-columns: repeat({GRID_SIZE[1]}, 1fr); gap: 5px;'>\"\n","for encoded_img in encoded_images:\n","    html += f\"<img src='data:image/png;base64,{encoded_img}' width='{IMAGE_SIZE[0]}' height='{IMAGE_SIZE[1]}'/>\"\n","html += \"</div>\"\n","\n","# Display images in notebook\n","display(HTML(html))\n","\n","# Save one sample image\n","if example_image is not None:\n","    example_image_path = f\"{dataset_shortname}_sample_image.png\"\n","    plt.imsave(example_image_path, example_image)\n","    print(f\"Sample image saved to: {example_image_path}\")"]},{"cell_type":"markdown","metadata":{"id":"1W0bFn8FJg_n"},"source":["## Save Output\n","- Save example image\n","- Save notebook to visualize the image\n","\n","PS: When running the notebook via Colab, you need to download the sample image manually and then place it in the `data_preview` folder in the `fish-datasets` repository."]}],"metadata":{"kernelspec":{"display_name":"venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}