{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9N5j-f2r0ks",
        "outputId": "0b269303-2b63-41b9-d453-98800e41eb54"
      },
      "outputs": [],
      "source": [
        "!pip install supervision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gF0-EVmPqFUl",
        "outputId": "565c5aea-7177-499c-c70e-6e3b854c6e9f"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import supervision as sv\n",
        "from pathlib import Path\n",
        "import random\n",
        "\n",
        "# Update the dataset short name and directory\n",
        "dataset_shortname = \"brackishmot\"\n",
        "data_dir = Path(\"/mnt/data/tmp/\") / dataset_shortname\n",
        "data_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# Use the Kaggle API to download and unzip the dataset\n",
        "# (Make sure the Kaggle API is installed and your credentials are configured)\n",
        "!kaggle datasets download -d maltepedersen/brackishmot -p {data_dir} --unzip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdX7RWvSsaeM",
        "outputId": "77b6ece4-77ef-418f-ffd1-628e45d8091e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "\n",
        "# Define paths and parameters\n",
        "dataset_root = data_dir / \"BrackishMOT\"\n",
        "split = \"train\"\n",
        "sequences = ['brackishMOT-97','brackishMOT-22','brackishMOT-70',\n",
        "             'brackishMOT-07','brackishMOT-53','brackishMOT-42']\n",
        "labels = ['fish', 'crab', 'shrimp', 'starfish', 'small fish', 'jellyfish']\n",
        "\n",
        "# Initialize COCO dictionary\n",
        "coco_dict = {\"images\": [], \"annotations\": [], \"categories\": []}\n",
        "\n",
        "# Create categories (assuming class IDs are 1-indexed)\n",
        "for i, label in enumerate(labels):\n",
        "    coco_dict[\"categories\"].append({\n",
        "        \"id\": i + 1,\n",
        "        \"name\": label,\n",
        "        \"supercategory\": \"none\"\n",
        "    })\n",
        "\n",
        "ann_id = 1\n",
        "image_id = 1\n",
        "\n",
        "for seq in sequences:\n",
        "    seq_img_dir = dataset_root / split / seq / \"img1\"\n",
        "    seq_gt_path = dataset_root / split / seq / \"gt\" / \"gt.txt\"\n",
        "\n",
        "    # Read the ground truth file\n",
        "    df = pd.read_csv(seq_gt_path, header=None)\n",
        "    df.columns = ['frame','id','left','top','width','height','conf','class','visibility']\n",
        "\n",
        "    # Process each image in the sequence\n",
        "    for img_file in sorted(os.listdir(seq_img_dir)):\n",
        "        try:\n",
        "            frame_number = int(os.path.splitext(img_file)[0])\n",
        "        except Exception as e:\n",
        "            print(f\"Skipping {img_file}: {e}\")\n",
        "            continue\n",
        "\n",
        "        # Open image to get width and height\n",
        "        img_path = seq_img_dir / img_file\n",
        "        try:\n",
        "            with Image.open(img_path) as img:\n",
        "                width, height = img.size\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading {img_path}: {e}\")\n",
        "            continue\n",
        "\n",
        "        # Add image entry (store relative path starting from the split folder)\n",
        "        coco_dict[\"images\"].append({\n",
        "            \"id\": image_id,\n",
        "            \"file_name\": os.path.join(seq, \"img1\", img_file),\n",
        "            \"width\": width,\n",
        "            \"height\": height\n",
        "        })\n",
        "\n",
        "        # Filter annotations for the current frame\n",
        "        df_frame = df[df[\"frame\"] == frame_number]\n",
        "        for _, row in df_frame.iterrows():\n",
        "            bbox = [\n",
        "                int(row['left']),\n",
        "                int(row['top']),\n",
        "                int(row['width']),\n",
        "                int(row['height'])\n",
        "            ]\n",
        "            coco_dict[\"annotations\"].append({\n",
        "                \"id\": ann_id,\n",
        "                \"image_id\": image_id,\n",
        "                \"category_id\": int(row['class']),\n",
        "                \"bbox\": bbox,\n",
        "                \"area\": int(row['width']) * int(row['height']),\n",
        "                \"iscrowd\": 0,\n",
        "            })\n",
        "            ann_id += 1\n",
        "\n",
        "        image_id += 1\n",
        "\n",
        "# Save the converted COCO JSON\n",
        "annotations_path = data_dir / \"brackishmot_coco.json\"\n",
        "with open(annotations_path, \"w\") as f:\n",
        "    json.dump(coco_dict, f)\n",
        "\n",
        "print(f\"COCO annotations saved to: {annotations_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 890
        },
        "id": "mT252sNsyMc5",
        "outputId": "e70f2234-8543-43f3-f98c-675028fbd9e5"
      },
      "outputs": [],
      "source": [
        "import supervision as sv\n",
        "from pathlib import Path\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the images directory (adjust this if your structure is different)\n",
        "# Assuming dataset_root is already defined as: data_dir / \"BrackishMOT\"\n",
        "images_directory_path = dataset_root / \"train\"  # This should contain your sequence folders (e.g., brackishMOT-97, etc.)\n",
        "\n",
        "# Load the dataset using the COCO annotations we just created\n",
        "dataset = sv.DetectionDataset.from_coco(\n",
        "    images_directory_path=str(images_directory_path),\n",
        "    annotations_path=str(annotations_path),\n",
        ")\n",
        "\n",
        "print(f\"Loaded dataset with {len(dataset)} images.\")\n",
        "print(f\"Dataset classes: {dataset.classes}\")\n",
        "\n",
        "# Initialize annotators for visualization\n",
        "box_annotator = sv.BoxAnnotator()\n",
        "label_annotator = sv.LabelAnnotator()\n",
        "\n",
        "# Visualize a grid of random samples from the dataset\n",
        "annotated_images = []\n",
        "image_example = None\n",
        "\n",
        "for _ in range(16):\n",
        "    idx = random.randint(0, len(dataset) - 1)\n",
        "    _, image, annotations = dataset[idx]\n",
        "\n",
        "    # Map class IDs to their label names\n",
        "    ann_labels = [dataset.classes[class_id] for class_id in annotations.class_id]\n",
        "\n",
        "    annotated_image = image.copy()\n",
        "    annotated_image = box_annotator.annotate(annotated_image, annotations)\n",
        "    annotated_image = label_annotator.annotate(annotated_image, annotations, ann_labels)\n",
        "    annotated_images.append(annotated_image)\n",
        "\n",
        "    if len(annotations) > 0:\n",
        "        image_example = annotated_image\n",
        "\n",
        "# Plot the grid of annotated images\n",
        "sv.plot_images_grid(\n",
        "    annotated_images,\n",
        "    grid_size=(4, 4),\n",
        "    titles=None,\n",
        "    size=(80, 48),\n",
        "    cmap=\"gray\"\n",
        ")\n",
        "\n",
        "# Optionally, save one preview image\n",
        "output_preview_dir = Path(\"data_preview\")\n",
        "output_preview_dir.mkdir(exist_ok=True, parents=True)\n",
        "plt.imsave(output_preview_dir / \"brackishmot_sample_image.png\", image_example)\n",
        "\n",
        "print(\"Visualization complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJlMUPdSo8RI",
        "outputId": "5d2f4383-7c32-4da1-8113-3534feb2e5ef"
      },
      "outputs": [],
      "source": [
        "print(f\"Dataset classes: {dataset.classes}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DATASET STATISTICS - Calculate exact counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5bFW_zXvzJHy",
        "outputId": "39f95a9f-f7fe-4db6-f91c-1b96c7e419eb"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def analyze_dataset_statistics(dataset_root, annotations_path, split=\"train\", sequences=None):\n",
        "    \"\"\"\n",
        "    Analyzes the BrackishMOT dataset to extract comprehensive statistics\n",
        "\n",
        "    Args:\n",
        "        dataset_root: Path to the dataset root directory\n",
        "        annotations_path: Path to the COCO annotations JSON file\n",
        "        split: Dataset split to analyze (default: \"train\")\n",
        "        sequences: List of sequence names to analyze (if None, all sequences will be analyzed)\n",
        "\n",
        "    Returns:\n",
        "        Dictionary containing dataset statistics\n",
        "    \"\"\"\n",
        "    stats = {}\n",
        "\n",
        "    # 1. Load COCO annotations file\n",
        "    print(f\"Loading annotations from {annotations_path}...\")\n",
        "    with open(annotations_path, 'r') as f:\n",
        "        coco_data = json.load(f)\n",
        "\n",
        "    # 2. Basic statistics from COCO annotations\n",
        "    stats['total_images'] = len(coco_data['images'])\n",
        "    stats['total_annotations'] = len(coco_data['annotations'])\n",
        "    stats['total_categories'] = len(coco_data['categories'])\n",
        "\n",
        "    # 3. Categories\n",
        "    stats['categories'] = [cat['name'] for cat in coco_data['categories']]\n",
        "\n",
        "    # 4. Per-category statistics\n",
        "    category_map = {cat['id']: cat['name'] for cat in coco_data['categories']}\n",
        "    category_counts = Counter([cat_id for ann in coco_data['annotations'] for cat_id in [ann['category_id']]])\n",
        "    stats['annotations_per_category'] = {category_map[cat_id]: count for cat_id, count in category_counts.items()}\n",
        "\n",
        "    # 5. Images per sequence\n",
        "    if not sequences:\n",
        "        # Extract sequence names from image file_name paths\n",
        "        all_file_names = [img['file_name'] for img in coco_data['images']]\n",
        "        sequences = list(set([file_name.split('/')[0] for file_name in all_file_names]))\n",
        "\n",
        "    sequence_counts = Counter([img['file_name'].split('/')[0] for img in coco_data['images']])\n",
        "    stats['images_per_sequence'] = {seq: sequence_counts.get(seq, 0) for seq in sequences}\n",
        "\n",
        "    # 6. Check image channels\n",
        "    # Sample a few images to detect channels\n",
        "    sample_image_paths = []\n",
        "    for seq in sequences:\n",
        "        seq_img_dir = os.path.join(dataset_root, split, seq, \"img1\")\n",
        "        if os.path.exists(seq_img_dir):\n",
        "            img_files = os.listdir(seq_img_dir)\n",
        "            if img_files:\n",
        "                sample_image_paths.append(os.path.join(dataset_root, split, seq, \"img1\", img_files[0]))\n",
        "                break\n",
        "\n",
        "    if sample_image_paths:\n",
        "        sample_img = Image.open(sample_image_paths[0])\n",
        "        if sample_img.mode == 'RGB':\n",
        "            stats['channels'] = 3\n",
        "            stats['color_mode'] = 'RGB'\n",
        "        elif sample_img.mode == 'L':\n",
        "            stats['channels'] = 1\n",
        "            stats['color_mode'] = 'Grayscale'\n",
        "        else:\n",
        "            stats['channels'] = len(sample_img.getbands())\n",
        "            stats['color_mode'] = sample_img.mode\n",
        "    else:\n",
        "        stats['channels'] = \"Unknown (no sample images found)\"\n",
        "        stats['color_mode'] = \"Unknown\"\n",
        "\n",
        "    # 7. Raw metadata format analysis\n",
        "    raw_formats = []\n",
        "    for seq in sequences:\n",
        "        gt_path = os.path.join(dataset_root, split, seq, \"gt\", \"gt.txt\")\n",
        "        if os.path.exists(gt_path):\n",
        "            with open(gt_path, 'r') as f:\n",
        "                first_line = f.readline().strip()\n",
        "                # Check if CSV format\n",
        "                delimiter = ',' if ',' in first_line else ' '\n",
        "                column_count = len(first_line.split(delimiter))\n",
        "                raw_formats.append(f\"{seq}: {column_count} columns with delimiter '{delimiter}'\")\n",
        "\n",
        "    stats['raw_format_info'] = raw_formats\n",
        "\n",
        "    # 8. Additional statistics\n",
        "    # Calculate annotations per image\n",
        "    image_ids = [ann['image_id'] for ann in coco_data['annotations']]\n",
        "    annotations_per_image = Counter(image_ids)\n",
        "    stats['avg_annotations_per_image'] = sum(annotations_per_image.values()) / len(annotations_per_image)\n",
        "    stats['max_annotations_per_image'] = max(annotations_per_image.values())\n",
        "    stats['min_annotations_per_image'] = min(annotations_per_image.values())\n",
        "\n",
        "    # 9. Generate visualizations\n",
        "    # Category distribution\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    categories = list(stats['annotations_per_category'].keys())\n",
        "    counts = list(stats['annotations_per_category'].values())\n",
        "    plt.bar(categories, counts)\n",
        "    plt.title('Annotations per Category')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('category_distribution.png')\n",
        "\n",
        "    # Sequence distribution\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sequences = list(stats['images_per_sequence'].keys())\n",
        "    counts = list(stats['images_per_sequence'].values())\n",
        "    plt.bar(sequences, counts)\n",
        "    plt.title('Images per Sequence')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('sequence_distribution.png')\n",
        "\n",
        "    # Print summary statistics\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"BrackishMOT Dataset Statistics Summary\")\n",
        "    print(f\"{'='*50}\")\n",
        "    print(f\"Total Images: {stats['total_images']}\")\n",
        "    print(f\"Total Annotations: {stats['total_annotations']}\")\n",
        "    print(f\"Categories ({stats['total_categories']}): {', '.join(stats['categories'])}\")\n",
        "    print(f\"Color Mode: {stats['color_mode']} ({stats['channels']} channels)\")\n",
        "    print(f\"Average Annotations per Image: {stats['avg_annotations_per_image']:.2f}\")\n",
        "    print(f\"\\nAnnotations per Category:\")\n",
        "    for cat, count in stats['annotations_per_category'].items():\n",
        "        print(f\"  - {cat}: {count}\")\n",
        "    print(f\"\\nImages per Sequence:\")\n",
        "    for seq, count in stats['images_per_sequence'].items():\n",
        "        print(f\"  - {seq}: {count}\")\n",
        "    print(f\"\\nRaw Format Information:\")\n",
        "    for fmt in stats['raw_format_info']:\n",
        "        print(f\"  - {fmt}\")\n",
        "    print(f\"{'='*50}\")\n",
        "\n",
        "    return stats\n",
        "\n",
        "# Add this at the end of your notebook to calculate and display the statistics\n",
        "if __name__ == \"__main__\" or True:  # This will run in Jupyter notebook\n",
        "    # Define paths (make sure these match your existing paths)\n",
        "    dataset_root = data_dir / \"BrackishMOT\"\n",
        "    annotations_path = data_dir / \"brackishmot_coco.json\"\n",
        "    sequences = ['brackishMOT-97','brackishMOT-22','brackishMOT-70',\n",
        "                 'brackishMOT-07','brackishMOT-53','brackishMOT-42']\n",
        "\n",
        "    # Run the analysis\n",
        "    dataset_stats = analyze_dataset_statistics(\n",
        "        dataset_root=dataset_root,\n",
        "        annotations_path=annotations_path,\n",
        "        split=\"train\",\n",
        "        sequences=sequences\n",
        "    )\n",
        "\n",
        "    # You can also save the stats to a JSON file for later reference\n",
        "    with open(data_dir / \"brackishmot_statistics.json\", 'w') as f:\n",
        "        # Convert any non-serializable values to strings\n",
        "        serializable_stats = {k: (str(v) if not isinstance(v, (dict, list, str, int, float, bool, type(None))) else v)\n",
        "                             for k, v in dataset_stats.items()}\n",
        "        json.dump(serializable_stats, f, indent=2)\n",
        "\n",
        "    print(f\"Statistics saved to {data_dir / 'brackishmot_statistics.json'}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
