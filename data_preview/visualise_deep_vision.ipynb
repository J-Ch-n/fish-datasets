{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing Template\n",
    "This notebook was used to download, analyze and process the data from the NOAA Pudget Sound dataset.\n",
    "\n",
    "You can use this template to process your own dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import supervision as sv\n",
    "from pathlib import Path\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the Data\n",
    "- If you want to use the `unzip` command you might need to install it. On linux, run `sudo apt-get install unzip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_shortname = \"deep_vision\"\n",
    "data_dir = Path(\"/tmp/data/\") / dataset_shortname\n",
    "data_dir.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"https://ftp.nmdc.no/nmdc/IMR/MachineLearning/fishDatasetSimulationAlgorithm.zip\"\n",
    "\n",
    "data_path = data_dir / \"images.zip\"\n",
    "\n",
    "!wget -O {data_path} {data}\n",
    "\n",
    "!unzip {data_path} -d {data_dir}\n",
    "\n",
    "!rm {data_path}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = data_dir / \"fish_dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the annotations\n",
    "Turn into COCO format readable by `supervision` library, for easy visualization and conversion to other formats.\n",
    "- The dataset has annotations group by year and divided into train and test splits\n",
    "- Read all the annotations across 2017 and 2018; and acrosss both train and test splits.\n",
    "- Create a `supervision` dataset with all annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csvs_to_coco(csv_files, output_json):\n",
    "    \"\"\"\n",
    "    Converts multiple CSV files with annotations in the format:\n",
    "      relative_image_path,xmin,ymin,xmax,ymax,label\n",
    "    to a COCO-format JSON file with \"images\", \"annotations\", and \"categories\".\n",
    "    The base_images_path is prepended to the relative image paths.\n",
    "    \n",
    "    Args:\n",
    "        csv_files (list of str or Path): List of paths to the CSV files.\n",
    "        output_json (str or Path): Path to save the output COCO JSON.\n",
    "    \"\"\"\n",
    "    # Dictionaries for images and categories; list for annotations\n",
    "    images = {}\n",
    "    annotations = []\n",
    "    categories = {}\n",
    "    \n",
    "    ann_id = 1   # Unique annotation id\n",
    "    image_id = 1 # Unique image id\n",
    "\n",
    "    # Process each CSV file\n",
    "    for csv_file in csv_files:\n",
    "        with csv_file.open('r', newline='') as f:\n",
    "            reader = csv.reader(f)\n",
    "            for row in reader:\n",
    "                if len(row) != 6:\n",
    "                    continue\n",
    "                rel_file_name, xmin, ymin, xmax, ymax, label = row\n",
    "\n",
    "                # Remove any leading \"/\" from relative path if present\n",
    "                rel_file_name = rel_file_name.lstrip('/')\n",
    "                file_name = os.path.join(images_path, rel_file_name)\n",
    "\n",
    "                try:\n",
    "                    xmin, ymin, xmax, ymax = int(xmin), int(ymin), int(xmax), int(ymax)\n",
    "                except ValueError:\n",
    "                    # Skip rows with invalid coordinate data\n",
    "                    continue\n",
    "\n",
    "                width = xmax - xmin\n",
    "                height = ymax - ymin\n",
    "\n",
    "                # Add image entry if not already added\n",
    "                if file_name not in images:\n",
    "                    images[file_name] = {\n",
    "                        \"id\": image_id,\n",
    "                        \"file_name\": file_name,\n",
    "                        \"width\": None,   # Optionally, set the width if known\n",
    "                        \"height\": None   # Optionally, set the height if known\n",
    "                    }\n",
    "                    image_id += 1\n",
    "\n",
    "                # Add category entry if not already added\n",
    "                if label not in categories:\n",
    "                    cat_id = len(categories) + 1  # unique category id\n",
    "                    categories[label] = {\n",
    "                        \"id\": cat_id,\n",
    "                        \"name\": label,\n",
    "                        \"supercategory\": label  # or assign a default supercategory\n",
    "                    }\n",
    "                cat_id = categories[label][\"id\"]\n",
    "\n",
    "                # Create annotation entry\n",
    "                ann = {\n",
    "                    \"id\": ann_id,\n",
    "                    \"image_id\": images[file_name][\"id\"],\n",
    "                    \"category_id\": cat_id,\n",
    "                    \"bbox\": [xmin, ymin, width, height],  # COCO format: [x, y, width, height]\n",
    "                    \"area\": width * height,\n",
    "                    \"iscrowd\": 0\n",
    "                }\n",
    "                annotations.append(ann)\n",
    "                ann_id += 1\n",
    "\n",
    "    # Convert dictionaries to lists\n",
    "    coco_images = list(images.values())\n",
    "    coco_categories = list(categories.values())\n",
    "    \n",
    "    coco_dict = {\n",
    "        \"images\": coco_images,\n",
    "        \"annotations\": annotations,\n",
    "        \"categories\": coco_categories\n",
    "    }\n",
    "    \n",
    "    with open(output_json, \"w\") as f:\n",
    "        json.dump(coco_dict, f, indent=4)\n",
    "    \n",
    "    print(f\"COCO annotations saved to {output_json}\")\n",
    "    print(f\"Number of images: {len(coco_images)}\")\n",
    "    print(f\"Number of annotations: {len(annotations)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = [data_dir / \"fish_dataset/2017/train/source-train2017-annotations.csv\",\n",
    "                    data_dir / \"fish_dataset/2017/test/test_2017_annotations.csv\",\n",
    "                    data_dir / \"fish_dataset/2018/train/source-train2018-annotations.csv\",\n",
    "                    data_dir / \"fish_dataset/2018/test/test_2018_annotations.csv\"]\n",
    "                    \n",
    "json_annotations_path = data_dir / \"combined_coco_annotations.json\"\n",
    "csvs_to_coco(csv_files, json_annotations_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise\n",
    "To visualise we need to extract 16 images randomly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sv.DetectionDataset.from_coco(\n",
    "    images_directory_path=str(images_path),\n",
    "    annotations_path=str(json_annotations_path),\n",
    ")\n",
    "\n",
    "print(f\"Dataset length: {len(dataset)}\")\n",
    "print(f\"Dataset classes: {dataset.classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_annotator = sv.BoxAnnotator()\n",
    "label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "image_example = None\n",
    "\n",
    "annotated_images = []\n",
    "for _ in range(16):\n",
    "    i = random.randint(0, len(dataset))\n",
    "    \n",
    "    _, image, annotations = dataset[i]\n",
    "\n",
    "    labels = [dataset.classes[class_id] for class_id in annotations.class_id]\n",
    "\n",
    "    annotated_image = image.copy()\n",
    "    annotated_image = box_annotator.annotate(annotated_image, annotations)\n",
    "    annotated_image = label_annotator.annotate(annotated_image, annotations, labels)\n",
    "    annotated_images.append(annotated_image)\n",
    "    \n",
    "    if len(annotations) > 0:\n",
    "        image_example = annotated_image\n",
    "    \n",
    "sv.plot_images_grid(\n",
    "    annotated_images,\n",
    "    grid_size=(4, 4),\n",
    "    titles=None,\n",
    "    size=(20, 12),\n",
    "    cmap=\"gray\"\n",
    ")\n",
    "\n",
    "plt.imsave(f\"{dataset_shortname}_sample_image.png\", image_example)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Output\n",
    "- Save example image\n",
    "- Save notebook to visualize the image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fish_detection_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
